---
date: 2024-03-4
title: 13、使用深度和法线纹理
weight: 13
---
## 如何获取？
深度值来自于顶点变换后得到的NDC（归一化设备坐标）中，由于使用了透视投影矩阵，所以最终的深度值是非线性的。并且NDC中z范围为[-1, 1]还需要映射到[0, 1]中，才能作为深度图像。
{{< katex display >}}
d = 0.5\cdot z_{ndc} + 0.5
{{< /katex >}}

在Unity中，深度纹理可直接来自于深度缓存，也可以由一个单独的Pass渲染而得，这取决于使用的渲染和硬件。通常如果使用延迟渲染可以访问到存储在G-buffer中的深度缓存。当无法直接获取深度缓存时，深度和法线是通过一个单独Pass渲染而得到的。Unity会选择渲染类型为Opaque的物体并判断渲染队列是否小于等于2500（Background、Geometry、AlphaTest），满足则把它加入深度和法线纹理中。要让物体能够出现在深度和法线纹理中，必须在shader中设置正确的renderType标签。

若只申请获取深度纹理，通常是24或16为，取决于深度缓存的精度。\
若要获取深度和法线，unity会创建一张屏幕分辨率相同、精度为32的纹理，法线存入RG通道，深度存入BA通道。

获取深度值后，需要将其转为线性的深度值，可以使用LinearEyeDepth把深度纹理采样的结果转换到视角空间下，Linear01Depth返回一个范围在[0, 1]的线性深度值。

如果获取深度和法线纹理使用DecodeDepthNormal进行解码，得到[0, 1]深度和视角空间下法线。

## 运动模糊
另一种更广泛的运动模糊方法是是用速度映射图，该图存储每个像素的速度，然后来决定模糊的方向和大小。

生成速度缓存有多种方法，一种是把场景所有物体渲染到一张纹理中，这需要修改场景所有物体的shader代码。也可以使用深度纹理在片元着色器中为每个像素计算其世界空间下的位置，再计算前一帧和当前帧的位置差，生成该像素的速度。
{{< details title="depthmap" open=true >}}
```c#
public class depthmap : posteffect
{
    public Shader motionblurshader;
    private Material motionblurmat = null;
    private Camera myCamera;

    private Matrix4x4 previousViewProjectionMatrix;

    [Range(0.0f, 1.0f)]
    public float blurSize = 0.5f;
    public Material material
    {
        get
        {
            motionblurmat = CheckShaderAndCreateMaterial(motionblurshader, motionblurmat);
            return motionblurmat;
        }
    }
    public Camera camera
    {
        get
        {
            if(myCamera == null)
            {
                myCamera = GetComponent<Camera>();
            }
            return myCamera;
        }
    }

    private void OnEnable()
    {
        camera.depthTextureMode |= DepthTextureMode.Depth;      //获取深度值
    }

    private void OnRenderImage(RenderTexture source, RenderTexture destination)
    {
        if(material != null)
        {
            material.SetFloat("_BlurSizse", blurSize); 

            material.SetMatrix("_PreviousViewProjectionMatrix", previousViewProjectionMatrix);              //前一帧的视角、投影矩阵
            Matrix4x4 currentViewProjectionMatrix = camera.projectionMatrix * camera.worldToCameraMatrix;   //当前帧的视角、投影矩阵
            Matrix4x4 currentViewProjectionInverseMatrix = currentViewProjectionMatrix.inverse;             //求逆
            material.SetMatrix("_CurrentViewProjectionInverseMatrix", currentViewProjectionInverseMatrix);  //当前帧的视角、投影矩阵的逆
            previousViewProjectionMatrix = currentViewProjectionMatrix;                                     //存储当前帧，下次调用onrenderimage即为上一帧

            Graphics.Blit(source, destination, material);                                                   
        }
        else
        {
            Graphics.Blit(source, destination);
        }
    }
}
```
{{< /details >}}



{{< details title="depthmap" open=true >}}

```shader
Properties{
        _MainTex("Base(RGB)",2D) = "white"{}
        _BlurSizse("Blur Sizse", Float) = 1.0
    }

    SubShader{
        CGINCLUDE
        #include"UnityCG.cginc"
        sampler2D _MainTex;
        half4 _MainTex_TexelSize;
        sampler2D _CameraDepthTexture;      //深度纹理
        float4x4 _CurrentViewProjectionInverseMatrix;
        float4x4 _PreviousViewProjectionMatrix;
        half _BlurSizse;

        struct v2f{
            float4 pos : SV_POSITION;
            half2 uv : TEXCOORD0;
            half2 uv_depth : TEXCOORD1;
        };

        v2f vert(appdata_img v){
            v2f o;
            o.pos = UnityObjectToClipPos(v.vertex);
            o.uv = v.texcoord;
            o.uv_depth = v.texcoord;

            #if UNITY_UV_STARTS_AT_TOP
            if(_MainTex_TexelSize.y<0)
                o.uv_depth.y = 1-o.uv_depth.y;
            #endif
            return o;
        }
        fixed4 frag(v2f i) : SV_Target{
            float d = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, i.uv_depth);        //取样深度纹理，此时为非线性，范围为[0, 1]
            float4 H = float4(i.uv.x*2 -1, i.uv.y*2 - 1, d*2 - 1, 1);               //从[0, 1]映射到[-1, 1]
            float4 D = mul(_CurrentViewProjectionInverseMatrix, H);                 //回到世界空间，这里乘以视角投影矩阵的逆
            float4 worldPos = D/D.w;                                                //得到世界空间坐标(NDC)

            float4 currentPos = H;                                                  //当前帧NDC值
            float4 previousPos = mul(_PreviousViewProjectionMatrix, worldPos);      //当前帧位置转换到上一帧NDC，这里摄像机的观察投影矩阵是在变化的，也就是摄像机在动
            previousPos /= previousPos.w;                                           //当前世界坐标在上一帧NDC中的值

            float2 velocity = (currentPos.xy - previousPos.xy)/2.0f;                //速度值

            float2 uv = i.uv;
            float4 c = tex2D(_MainTex, uv);
            uv += velocity * _BlurSizse;                                            //对纹理偏移
            for(int it = 1; it<3; it++)
            {
                float4 currentColor = tex2D(_MainTex, uv);                          //取样
                c+= currentColor;                                                   //叠加
            }
            c/=3;                                                                   //取平均
            return fixed4(c.rgb, 1.0);                          
        }
        ENDCG

        Pass{
            ZTest Always Cull Off Zwrite Off
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            ENDCG
        }
    }
    FallBack Off
```
{{< /details >}}


## 全局雾效
基于屏幕后处理的全局雾效关键是，根据深度纹理来重建每个像素在世界空间下的位置。要快速从深度纹理中重建世界坐标，首先对图像空间下的视锥体射线进行插值，然后把该射线和线性化后的视角空间下的深度值相乘，再加上摄像机的世界位置，就可以得到该像素在世界空间下的位置。
```shader
float4 worldPos = _WorldSpaceCameraPos + linearDepth * interpolatedRay;
```
interpolatedRay由顶点着色器输出并插值后得到的射线，包含了该像素到摄像机的方向和距离信息。

interpolatedRay来源于对裁剪平面4个角的插值：
{{< katex display >}}
halfHeight = Near \times tan{\frac{FOV}{2}}
{{< /katex >}}

{{< katex display >}}
toTop = camera.up \times halfHeight
{{< /katex >}}

{{< katex display >}}
toRight = camera.right \times halfHeight \cdot aspect
{{< /katex >}}

4个角对于摄像机的方向：
{{< katex display >}}
TL = camera.forward\cdot Near + toTop - toRight\\
TR = camera.forward\cdot Near + toTop + toRight\\
BL = camera.forward\cdot Near - toTop - toRight\\
BR = camera.forward\cdot Near - toTop + toRight
{{< /katex >}}

线性深度值为摄像机z方向上的距离，所以现在还不能使用深度值和4个角的单位方向的乘积计算距离摄像机的偏移量；根据相似三角形原理计算欧式距离dist，也就是摄像机到该点的距离：
{{< katex display >}}
\frac{depth}{dist} = \frac{Near}{|TL|}
{{< /katex >}}

{{< katex display >}}
dist = \frac{|TL|}{Near}\times depth
{{< /katex >}}
4个点相互对称，使用一个因子和单位向量相乘即可得到对应向量值：
{{< katex display >}}
scale = \frac{|TL|}{|Near|}
{{< /katex >}}

{{< katex display >}}
Ray_{TL} = \frac{TL}{|TL|}\times scale
{{< /katex >}}
TR、BL、BR同理。

把4个向量传给顶点着色器，顶点着色器根据当前位置选择它所对应的向量，然后再将其输出，经过插值后传给片段着色器得到interpolatedRay。

在简单的雾效中，需要计算一个雾效系数f，作为混合原始颜色和雾的颜色的混合系数：
```shader
float3 afterFog = f * fogColor + (1-f) * origColor;
```
f有很多计算方法，unity内置的雾效实现中支持三种计算方式：
- 线性（Linear）
- 指数（Exponential）
- 指数平方（Exponential Squared）

当给定距离z后，计算公式分别如下：

Linear：
{{< katex display >}}
f = \frac{d_{max} - |z|}{d_{max} - d_{min}}, d_{max}，d_{min}表示受雾影响的最小和最大距离
{{< /katex >}}

Exponential：
{{< katex display >}}
f = e^{-d\cdot |z|}，d为控制雾的浓度的参数
{{< /katex >}}

Exponential Squared：
{{< katex display >}}
f = e^{-(d-|z|)^2}，d为控制雾的浓度的参数
{{< /katex >}}

这里使用类似线性雾的计算方法，计算基于高度的雾效。
{{< details title="Fog.cs" open=true >}}
```c#
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

public class Fog : posteffect
{
    public Shader fogshader;
    private Material fogmat;
    private Camera mycamera;
    private Transform mycameratransform;

    [Range(0.0f, 3.0f)]
    public float fogDensity = 1.0f;         //控制雾的浓度
    public Color fogColor = Color.white;     //雾的颜色

    public float fogStart = 0.0f;           //起始位置
    public float fogEnd = 2.0f;             //终点位置

    public Material material
    {
        get
        {
            fogmat = CheckShaderAndCreateMaterial(fogshader, fogmat);
            return fogmat;
        }
    }
    public Camera camera
    {
        get
        {
            if (mycamera == null)
                mycamera = GetComponent<Camera>();      //获取camera组件
            return mycamera;
        }
    }
    public Transform cameratransform
    {
        get
        {
            if (mycameratransform == null)
                mycameratransform = GetComponent<Transform>();
            return mycameratransform;
        }
    }
    private void OnEnable()
    {
        camera.depthTextureMode |= DepthTextureMode.Depth;      //获取深度
    }

    private void OnRenderImage(RenderTexture source, RenderTexture destination)
    {
        if(material != null)
        {
            Matrix4x4 frustumCorners = Matrix4x4.identity;

            float fov = camera.fieldOfView;
            float near = camera.nearClipPlane;
            float far = camera.farClipPlane;
            float aspect = camera.aspect;

            float halfHight = near * Mathf.Tan(fov * 0.5f * Mathf.Deg2Rad);
            Vector3 toRight = cameratransform.right * halfHight * aspect;
            Vector3 toTop = cameratransform.up * halfHight;

            Vector3 topLeft = cameratransform.forward * near  - toRight + toTop;
            Vector3 topRight = cameratransform.forward * near + toRight + toTop;
            Vector3 bottomRight = cameratransform.forward * near + toRight - toTop;
            Vector3 bottomLeft = cameratransform.forward * near - toRight - toTop;
            float scale = topLeft.magnitude / near;
            topLeft.Normalize();
            topRight.Normalize();
            bottomRight.Normalize();
            bottomLeft.Normalize();
            topLeft *= scale;
            topRight *= scale;
            bottomRight *= scale;
            bottomLeft *= scale;

            frustumCorners.SetRow(0, bottomLeft);           //4组向量放到一起，变为矩阵
            frustumCorners.SetRow(1, bottomRight);
            frustumCorners.SetRow(2, topRight);
            frustumCorners.SetRow(3, topLeft);

            material.SetMatrix("_FrustumCornersRay", frustumCorners);
            //material.SetMatrix("_ViewProjectionInverseMatrix", (camera.projectionMatrix * camera.worldToCameraMatrix));

            material.SetFloat("_FogDensity", fogDensity);
            material.SetColor("_FogColor", fogColor);
            material.SetFloat("_FogStart", fogStart);
            material.SetFloat("_FogEnd", fogEnd);
            Graphics.Blit(source, destination, material);
        }
        else
        {
            Graphics.Blit(source, destination);
        }
    }
}

```
{{< /details >}}

{{< details title="Fog" open=true >}}
```shader
Shader "posteffect/Fog"
{
    Properties{
        _MainTex("Base(RGB)", 2D) = "white"{}
        _FogDensity("Fog Density", Float) = 1.0
        _FogColor("Fog Color", Color) = (1,1,1,1)
        _FogStart("Fog Start", Float) = 0.0
        _FogEnd("Fog End", Float) = 1.0
    }
    SubShader{
        CGINCLUDE
        #include"UnityCG.cginc"
        float4x4 _FrustumCornersRay;            //4组向量
        sampler2D _MainTex;
        half4 _MainTex_TexelSize;
        sampler2D _CameraDepthTexture;          //深度
        half _FogDensity;
        fixed4 _FogColor;
        float _FogStart;
        float _FogEnd;
        
        struct v2f{
            float4 pos : SV_POSITION;
            half2 uv : TEXCOORD0;
            half2 uv_depth : TEXCOORD1;
            float4 interpolatedRay : TEXCOORD2;
        };

        v2f vert(appdata_img v){
            v2f o;
            o.pos = UnityObjectToClipPos(v.vertex);
            o.uv = v.texcoord;
            o.uv_depth = v.texcoord;

            #if UNITY_UV_STARTS_AT_TOP
            if(_MainTex_TexelSize.y < 0)
                o.uv_depth.y = 1-o.uv_depth.y;
            #endif

            int index = 0;
            if(v.texcoord.x < 0.5 && v.texcoord.y < 0.5)                //根据纹理位置设置索引，选择4组向量中对应向量
                index = 0;
            else if(v.texcoord.x > 0.5 && v.texcoord.y < 0.5)
                index = 1;
            else if(v.texcoord.x > 0.5 && v.texcoord.y > 0.5)
                index = 2;
            else
                index = 3;

            #if UNITY_UV_STARTS_AT_TOP
            if(_MainTex_TexelSize.y < 0)
                index = 3 - index;
            #endif
            o.interpolatedRay = _FrustumCornersRay[index];              //传入片元着色器
            return o;
        }
        fixed4 frag(v2f i) : SV_Target{
            float linearDepth = LinearEyeDepth(SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, i.uv_depth));      //线性深度
            float3 worldPos = _WorldSpaceCameraPos + linearDepth * i.interpolatedRay.xyz;                   //世界坐标

            float fogDensity = (_FogEnd - worldPos.y) / (_FogEnd - _FogStart);                              //基于高度的雾效
            fogDensity = saturate(fogDensity * _FogDensity);

            fixed4 finalColor = tex2D(_MainTex, i.uv);
            finalColor.rgb = lerp(finalColor.rgb, _FogColor.rgb, fogDensity);                               //混合

            return finalColor;
        }
        ENDCG
        Pass{
            ZTest Always Cull Off ZWrite Off
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            ENDCG
        }
    }
    FallBack Off
}
```
{{< /details >}}

## 边缘检测
这里使用Roberts算子在深度和法线纹理上进行边缘检测。Roberts算子本质是计算左上角和右下角的差值，乘以右上角和左下角的插值，作为评估边缘的依据。这里取对角线方向的深度或法线值，比较它们之间的差值，若通过某个阈值，就认为存在一条边。

{{< details title="normaledge.cs" open=true >}}
```c#
using UnityEngine;
using System.Collections;

public class normaledge : posteffect
{

	public Shader edgeDetectShader;
	private Material edgeDetectMaterial = null;
	public Material material
	{
		get
		{
			edgeDetectMaterial = CheckShaderAndCreateMaterial(edgeDetectShader, edgeDetectMaterial);
			return edgeDetectMaterial;
		}
	}

	[Range(0.0f, 1.0f)]
	public float edgesOnly = 0.0f;
	public Color edgeColor = Color.black;
	public Color backgroundColor = Color.white;
	public float sampleDistance = 1.0f;                                                     //采样距离，值越大，边越宽
	public float sensitivityDepth = 1.0f;                                                   //深度灵敏
	public float sensitivityNormals = 1.0f;                                                 //法线灵敏

	void OnEnable()
	{
		GetComponent<Camera>().depthTextureMode |= DepthTextureMode.DepthNormals;           //获取深度法线纹理
	}

	[ImageEffectOpaque]
	void OnRenderImage(RenderTexture src, RenderTexture dest)
	{
		if (material != null)
		{
			material.SetFloat("_EdgeOnly", edgesOnly);
			material.SetColor("_EdgeColor", edgeColor);
			material.SetColor("_BackgroundColor", backgroundColor);
			material.SetFloat("_SampleDistance", sampleDistance);
			material.SetVector("_Sensitivity", new Vector4(sensitivityNormals, sensitivityDepth, 0.0f, 0.0f));

			Graphics.Blit(src, dest, material);
		}
		else
		{
			Graphics.Blit(src, dest);
		}
	}
}
```
{{< /details >}}


{{< details title="normaledge" open=true >}}
```shader
Shader "posteffect/normaledge" {
	Properties {
		_MainTex ("Base (RGB)", 2D) = "white" {}
		_EdgeOnly ("Edge Only", Float) = 1.0
		_EdgeColor ("Edge Color", Color) = (0, 0, 0, 1)
		_BackgroundColor ("Background Color", Color) = (1, 1, 1, 1)
		_SampleDistance ("Sample Distance", Float) = 1.0
		_Sensitivity ("Sensitivity", Vector) = (1, 1, 1, 1)
	}
	SubShader {
		CGINCLUDE
		#include "UnityCG.cginc"
		sampler2D _MainTex;
		half4 _MainTex_TexelSize;
		fixed _EdgeOnly;
		fixed4 _EdgeColor;
		fixed4 _BackgroundColor;
		float _SampleDistance;
		half4 _Sensitivity;
		sampler2D _CameraDepthNormalsTexture;           //深度法线纹理
		
		struct v2f {
			float4 pos : SV_POSITION;
			half2 uv[5]: TEXCOORD0;
		};
		  
		v2f vert(appdata_img v) {
			v2f o;
			o.pos = UnityObjectToClipPos(v.vertex);
			
			half2 uv = v.texcoord;
			o.uv[0] = uv;
			
			#if UNITY_UV_STARTS_AT_TOP
			if (_MainTex_TexelSize.y < 0)
				uv.y = 1 - uv.y;
			#endif
			
			o.uv[1] = uv + _MainTex_TexelSize.xy * half2(1,1) * _SampleDistance;            //Roberts算子，这里还没有权重
			o.uv[2] = uv + _MainTex_TexelSize.xy * half2(-1,-1) * _SampleDistance;
			o.uv[3] = uv + _MainTex_TexelSize.xy * half2(-1,1) * _SampleDistance;
			o.uv[4] = uv + _MainTex_TexelSize.xy * half2(1,-1) * _SampleDistance;
					 
			return o;
		}
		
		half CheckSame(half4 center, half4 sample) {                //返回0或1，表示该像素是否为边缘
			half2 centerNormal = center.xy;                         //注：这里的法线还不是真正的法线，
			half2 sampleNormal = sample.xy;
			float centerDepth = DecodeFloatRG(center.zw);
			float sampleDepth = DecodeFloatRG(sample.zw);
			
			half2 diffNormal = abs(centerNormal - sampleNormal) * _Sensitivity.x;           
			int isSameNormal = (diffNormal.x + diffNormal.y) < 0.1;                         

			float diffDepth = abs(centerDepth - sampleDepth) * _Sensitivity.y;
			int isSameDepth = diffDepth < 0.1 * centerDepth;
			
			return isSameNormal * isSameDepth ? 1.0 : 0.0;
		}
		
		fixed4 fragRobertsCrossDepthAndNormal(v2f i) : SV_Target {
			half4 sample1 = tex2D(_CameraDepthNormalsTexture, i.uv[1]);
			half4 sample2 = tex2D(_CameraDepthNormalsTexture, i.uv[2]);
			half4 sample3 = tex2D(_CameraDepthNormalsTexture, i.uv[3]);
			half4 sample4 = tex2D(_CameraDepthNormalsTexture, i.uv[4]);
			
			half edge = 1.0;
			
			edge *= CheckSame(sample1, sample2);
			edge *= CheckSame(sample3, sample4);
			
			fixed4 withEdgeColor = lerp(_EdgeColor, tex2D(_MainTex, i.uv[0]), edge);
			fixed4 onlyEdgeColor = lerp(_EdgeColor, _BackgroundColor, edge);
			
			return lerp(withEdgeColor, onlyEdgeColor, _EdgeOnly);
		}
		
		ENDCG
		
		Pass { 
			ZTest Always Cull Off ZWrite Off
			CGPROGRAM      
			#pragma vertex vert  
			#pragma fragment fragRobertsCrossDepthAndNormal
			ENDCG  
		}
	} 
	FallBack Off
}
```
{{< /details >}}